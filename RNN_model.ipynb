{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras as keras\n",
    "\n",
    "from sys import argv,exit\n",
    "from datetime import datetime, date, timedelta\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,GRU, LSTM,Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_model(network_type, df,num_iterations,num_features,batch_size,hidden_layers,num_neurons,dropout_rate):\n",
    "\n",
    "    random.seed()\n",
    "    global net\n",
    "    net = Sequential()\n",
    "    \n",
    "    experiment = experiment = str(datetime.now()).replace(\":\",\"\").replace(\" \",\"\").replace(\"-\",\"\")[:14]\n",
    "    \n",
    "    learning_rate = 0.002\n",
    "    #This optimizer is usually a good choice for recurrent neural networks\n",
    "    #It is recommended to leave the parameters of this optimizer at their default values.\n",
    "    nadam = keras.optimizers.Nadam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "    optimizer = 'nadam'\n",
    "   \n",
    "    label = '08_close'\n",
    "    date_column = '00_date'\n",
    "\n",
    "    maxs =[]\n",
    "    mins =[]\n",
    "\n",
    "    def buildGRU(w_init=\"glorot_uniform\",act=\"tanh\"):\n",
    "        net.add(Dense(num_features,kernel_initializer=w_init,input_dim=num_features,activation='linear'))\n",
    "        net.add(Reshape((1,num_features)))\n",
    "        net.add(BatchNormalization())\n",
    "        for i in range(hidden_layers):\n",
    "            net.add(GRU(num_neurons,kernel_initializer=w_init,activation=act,return_sequences=True))\n",
    "            net.add(Dropout(dropout_rate))\n",
    "        net.add(GRU(num_neurons,kernel_initializer=w_init,activation=act,return_sequences=False))\n",
    "        net.add(Dropout(dropout_rate))\n",
    "        net.add(Dense(1,kernel_initializer=w_init,activation='linear'))\n",
    "        net.compile(optimizer=nadam,loss='mean_squared_error')\n",
    "        \n",
    "    def buildLSTM(w_init=\"glorot_uniform\",act=\"tanh\"):\n",
    "        net.add(Dense(num_features,kernel_initializer=w_init,input_dim=num_features,activation='linear'))\n",
    "        net.add(Reshape((1,num_features)))\n",
    "        net.add(BatchNormalization())\n",
    "        for i in range(hidden_layers):\n",
    "            net.add(LSTM(num_neurons,kernel_initializer=w_init,activation=act,return_sequences=True))\n",
    "            net.add(Dropout(dropout_rate))\n",
    "        net.add(LSTM(num_neurons,kernel_initializer=w_init,activation=act,return_sequences=False))\n",
    "        net.add(Dropout(dropout_rate))\n",
    "        net.add(Dense(1,kernel_initializer=w_init,activation='linear'))\n",
    "        net.compile(optimizer=nadam,loss='mean_squared_error')        \n",
    "        \n",
    "    def chart(real,predicted,xlabel,show=True):\n",
    "        plt.title('Real BTC price vs Predicted BTC price')\n",
    "        plt.plot(predicted,label='Predicted')\n",
    "        plt.plot(real, label='Real')\n",
    "        plt.ylabel('BTC/USD')\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.savefig(\"BTC_chart\"+experiment+\".png\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        if show:plt.show()\n",
    "\n",
    "    def loadData(df):\n",
    "        #column names\n",
    "        columns = df.columns.tolist()\n",
    "        columns = [x for x in columns if x != label] # removes the label column\n",
    "        columns = [x for x in columns if x != date_column] # removes the date column\n",
    "        columns = columns[:num_features] #first N features\n",
    "        #get the values for a given column\n",
    "        Y = df[label].values.tolist()\n",
    "        #get a data frame with selected columns\n",
    "        X = df[columns].values.tolist()\n",
    "        #for i in range(len(X)): X[i] = [float(k) for k in X[i]]\n",
    "        #number of features\n",
    "        #num_features = len(columns)\n",
    "        return X[:-1],Y[1:] # X[i] will predict Y[i+1]\n",
    "\n",
    "    def reduceVector(vec,getVal=False):\n",
    "        vect = []\n",
    "        mx,mn = max(vec),min(vec)\n",
    "        mx = mx+mn\n",
    "        mn = mn-((mx-mn)*0.4)\n",
    "        for x in vec:\n",
    "            vect.append((x-mn)/(mx-mn+sys.float_info.min))\n",
    "        if not getVal:return vect\n",
    "        else:return vect,mx,mn\n",
    "\n",
    "    def reduceValue(x,mx,mn):\n",
    "        return (x-mn)/(mx-mn+sys.float_info.min)\n",
    "\n",
    "    def augmentValue(x,mx,mn):\n",
    "        return (mx-mn)*x+mn\n",
    "\n",
    "    def reduceMatRows(data):\n",
    "        l = len(data[0])\n",
    "        for i in range(l):\n",
    "            v = []\n",
    "            for t in range(len(data)):\n",
    "                v.append(data[t][i])\n",
    "            v,mx,mn = reduceVector(v,getVal=True)\n",
    "            maxs.append(mx)\n",
    "            mins.append(mn)\n",
    "            for t in range(len(data)):\n",
    "                data[t][i] = v[t]\n",
    "        return data\n",
    "\n",
    "    def reduceCurrent(data):\n",
    "        for i in range(len(data)):\n",
    "            data[i] = reduceValue(data[i],maxs[i],mins[i])\n",
    "        return data\n",
    "    \n",
    "    def MASE(training_series, testing_series, prediction_series):\n",
    "        n = training_series.shape[0]\n",
    "        d = np.abs(  np.diff( training_series) ).sum()/(n-1)    \n",
    "        errors = np.abs(testing_series - prediction_series )\n",
    "        return errors.mean()/d    \n",
    "\n",
    "    #data loading:\n",
    "    data,Y = loadData(df)\n",
    "    #data normalization\n",
    "    data = reduceMatRows(data)\n",
    "    labels,m1,m2 =reduceVector(Y,getVal=True)\n",
    "\n",
    "    #Assembling Net:\n",
    "    if network_type == 'GRU': buildGRU()\n",
    "    else: buildLSTM()\n",
    "\n",
    "    # Data split: training (75,5%) validation (26,5%) testing (1,9%)\n",
    "    num_records = len(labels)\n",
    "    num_validation = 396\n",
    "    num_testing = 31\n",
    "    num_training = num_records-num_testing\n",
    "\n",
    "    training_X = data[:num_training]\n",
    "    training_Y = labels[:num_training]\n",
    "\n",
    "    testing_X = data[num_training:]\n",
    "    testing_Y = labels[num_training:]\n",
    "\n",
    "    #Training GRU\n",
    "    startTime = datetime.now()\n",
    "    with tf.device(\"/gpu:0\"): net.fit(training_X,training_Y,epochs=num_iterations,batch_size=batch_size)\n",
    "    #with tf.device(\"/gpu:0\"): net.fit(training_X,training_Y,epochs=10,batch_size=batch_size)\n",
    "    print(\"Training complete: \"+experiment,end=\"\\n\")\n",
    "    #net.save_weights(network_type+\"_model_\"+experiment+\".h5\")\n",
    "    #print(\"Model saved as \"+network_type+\"_model_\"+experiment+\".h5\")\n",
    "    training_time = datetime.now() - startTime\n",
    "    print(\"Training time:\", training_time)\n",
    "\n",
    "    ### Predict all over the dataset to build the chart\n",
    "    reals,preds = [],[]\n",
    "    startTime = datetime.now()\n",
    "    length = len(testing_Y)\n",
    "    for i in range(0,length):\n",
    "        x = np.array(testing_X[i]).reshape(1,num_features)\n",
    "        predicted = augmentValue(net.predict(x)[0],m1,m2)[0]\n",
    "        real = augmentValue(testing_Y[i],m1,m2)\n",
    "        preds.append(predicted)\n",
    "        reals.append(real)\n",
    "\n",
    "    RMSE_T = np.sqrt(mean_squared_error(reals, preds))\n",
    "    RMSE_D = np.sqrt(mean_squared_error(reals[:1], preds[:1]))\n",
    "    RMSE_W = np.sqrt(mean_squared_error(reals[:7], preds[:7]))\n",
    "    \n",
    "    # PLOTTING\n",
    "    chart(reals,preds,str(num_testing)+\" days (from September 1st, 2017)\")\n",
    "    chart(Y[:num_training]+reals,Y[:num_training]+preds,str(num_records)+\" days (from May 2nd, 2013)\")\n",
    "    chart((Y[:num_training]+reals)[num_training-10:],(Y[:num_training]+preds)[num_training-10:],\"zoom\")\n",
    "\n",
    "    print (\"Root Mean Squared Error (RMSE): %f\" % RMSE_T)\n",
    "    print (\"RMSE for the next day (1 day): %f\" % RMSE_D)\n",
    "    print (\"RMSE for the next week (7 days): %f\" % RMSE_W)\n",
    "\n",
    "    print(\"Num. iterations: \"+str(num_iterations),end=\"\\n\")\n",
    "    print(\"Batch size: \"+str(batch_size),end=\"\\n\")\n",
    "    print(\"Optimizer: \"+optimizer,end=\"\\n\")\n",
    "    print(\"Hidden layers: \"+str(hidden_layers),end=\"\\n\")\n",
    "    print(\"Dropout rate: \"+str(dropout_rate),end=\"\\n\")\n",
    "    print(\"Learning rate: \"+str(learning_rate),end=\"\\n\\n\")\n",
    "\n",
    "    dates = []\n",
    "    for i in range(31): dates+=[date(2017,9,1)+timedelta(days=i)]    \n",
    "    predictions = pandas.DataFrame({'date': dates, 'real': reals, 'predictions': preds })\n",
    "    print(predictions)\n",
    "    \n",
    "    results_columns = ['experiment','num_iterations','num_features','batch_size','hidden_layers','neurons','dropout','training_time', 'RMSE','RMSE_1D', 'RMSE_1W']\n",
    "    results = [[experiment,num_iterations,num_features,batch_size,hidden_layers,num_neurons,dropout_rate,training_time,RMSE_T,RMSE_D,RMSE_W]]\n",
    "    return pandas.DataFrame(results,columns=results_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER-PARAMETER OPTIMIZATION\n",
    "file_name = 'btc_multivariate.xlsx'\n",
    "df = pandas.read_excel(file_name)\n",
    "\n",
    "network_type = 'GRU'\n",
    "\n",
    "dr = RNN_model(df,50,11,100,1,10,0.1)\n",
    "for i in [100]: #iterations\n",
    "    for f in [11,75,213]: #features\n",
    "        for b in [100,300,500]:#batch_size\n",
    "            for l in [1,3,10]: #num_layers\n",
    "                for n in [10,100,500]: #num_neurons\n",
    "                    for d in [0.1,0.3]: #dropout_rate\n",
    "                        frames = [dr,RNN_model(network_type,df,i,f,b,l,n,d)]\n",
    "                        dr = pandas.concat(frames)\n",
    "            writer = pandas.ExcelWriter(network_type+'_output_'+str(i)+'_'+str(f)+'_'+str(b)+'.xlsx')\n",
    "            dr.to_excel(writer,'Sheet1')\n",
    "            writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPER-PARAMETER OPTIMIZATION\n",
    "file_name = 'btc_multivariate.xlsx'\n",
    "df = pandas.read_excel(file_name)\n",
    "\n",
    "network_type = 'LSTM'\n",
    "\n",
    "dr = RNN_model(df,50,11,100,1,10,0.1)\n",
    "for i in [100]: #iterations\n",
    "    for f in [11,75,213]: #features\n",
    "        for b in [100,300,500]:#batch_size\n",
    "            for l in [1,3,10]: #num_layers\n",
    "                for n in [10,100,500]: #num_neurons\n",
    "                    for d in [0.1,0.3]: #dropout_rate\n",
    "                        frames = [dr,RNN_model(network_type,df,i,f,b,l,n,d)]\n",
    "                        dr = pandas.concat(frames)\n",
    "            writer = pandas.ExcelWriter(network_type+'_output_'+str(i)+'_'+str(f)+'_'+str(b)+'.xlsx')\n",
    "            dr.to_excel(writer,'Sheet1')\n",
    "            writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
